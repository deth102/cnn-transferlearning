{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd98d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_LABELS: ['Bpfi', 'Bpfo', 'Misalign', 'Normal', 'Unbalance']\n",
      "LABEL_TO_IDX: {'Bpfi': 0, 'Bpfo': 1, 'Misalign': 2, 'Normal': 3, 'Unbalance': 4}\n",
      "SOURCE: 17850 3825 3825\n",
      "\n",
      "TARGET SPLIT:\n",
      "Train: 4800\n",
      "Val: 3150\n",
      "Test: 13050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\lt\\datn\\cnn transfer\\PrepareData\\DataLoader.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seg = torch.tensor(seg, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | S_train: 0.5908 T_train: 0.5654 | S_val: 0.8076 T_val: 0.5581 | avg_loss: 2.1340\n",
      "Saved best model (epoch 1) | combined = 0.6828\n",
      "Epoch 02 | S_train: 0.8524 T_train: 0.7290 | S_val: 0.9281 T_val: 0.5997 | avg_loss: 0.8207\n",
      "Saved best model (epoch 2) | combined = 0.7639\n",
      "Epoch 03 | S_train: 0.9267 T_train: 0.7557 | S_val: 0.9600 T_val: 0.5917 | avg_loss: 0.4924\n",
      "Saved best model (epoch 3) | combined = 0.7759\n",
      "Epoch 04 | S_train: 0.9568 T_train: 0.7578 | S_val: 0.9739 T_val: 0.6425 | avg_loss: 0.3222\n",
      "Saved best model (epoch 4) | combined = 0.8082\n",
      "Epoch 05 | S_train: 0.9714 T_train: 0.7642 | S_val: 0.9707 T_val: 0.6514 | avg_loss: 0.2397\n",
      "Saved best model (epoch 5) | combined = 0.8111\n",
      "Epoch 06 | S_train: 0.9788 T_train: 0.7662 | S_val: 0.9786 T_val: 0.6152 | avg_loss: 0.1838\n",
      "Epoch 07 | S_train: 0.9824 T_train: 0.7736 | S_val: 0.9880 T_val: 0.6721 | avg_loss: 0.1539\n",
      "Saved best model (epoch 7) | combined = 0.8300\n",
      "Epoch 08 | S_train: 0.9841 T_train: 0.7764 | S_val: 0.9898 T_val: 0.6921 | avg_loss: 0.1360\n",
      "Saved best model (epoch 8) | combined = 0.8409\n",
      "Epoch 09 | S_train: 0.9863 T_train: 0.7815 | S_val: 0.9880 T_val: 0.6873 | avg_loss: 0.1209\n",
      "Epoch 10 | S_train: 0.9887 T_train: 0.7838 | S_val: 0.9038 T_val: 0.7006 | avg_loss: 0.1057\n",
      "Epoch 11 | S_train: 0.9911 T_train: 0.7846 | S_val: 0.9914 T_val: 0.6860 | avg_loss: 0.0906\n",
      "Epoch 12 | S_train: 0.9906 T_train: 0.7778 | S_val: 0.9908 T_val: 0.6883 | avg_loss: 0.0862\n",
      "Epoch 13 | S_train: 0.9924 T_train: 0.7793 | S_val: 0.9890 T_val: 0.7070 | avg_loss: 0.0816\n",
      "Saved best model (epoch 13) | combined = 0.8480\n",
      "Epoch 14 | S_train: 0.9929 T_train: 0.7782 | S_val: 0.9903 T_val: 0.7025 | avg_loss: 0.0768\n",
      "Epoch 15 | S_train: 0.9943 T_train: 0.7735 | S_val: 0.9901 T_val: 0.7092 | avg_loss: 0.0719\n",
      "Saved best model (epoch 15) | combined = 0.8496\n",
      "Epoch 16 | S_train: 0.9934 T_train: 0.7712 | S_val: 0.9924 T_val: 0.7041 | avg_loss: 0.0715\n",
      "Epoch 17 | S_train: 0.9946 T_train: 0.7725 | S_val: 0.9888 T_val: 0.7019 | avg_loss: 0.0666\n",
      "Epoch 18 | S_train: 0.9948 T_train: 0.7675 | S_val: 0.9872 T_val: 0.7337 | avg_loss: 0.0639\n",
      "Saved best model (epoch 18) | combined = 0.8604\n",
      "Epoch 19 | S_train: 0.9955 T_train: 0.7647 | S_val: 0.9929 T_val: 0.7149 | avg_loss: 0.0619\n",
      "Epoch 20 | S_train: 0.9962 T_train: 0.7615 | S_val: 0.9814 T_val: 0.6987 | avg_loss: 0.0563\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from itertools import cycle\n",
    "from typing import Tuple\n",
    "\n",
    "# --- imports from your project ---\n",
    "from PrepareData.DataLoader import (\n",
    "    source_train_loader, source_val_loader,\n",
    "    target_train_loader, target_val_loader\n",
    ")\n",
    "from PrepareData.SignalSegments import LABEL_TO_IDX\n",
    "from Backbone.CNN1D import CNN1D\n",
    "from Backbone.CNN2D import CNN2D\n",
    "from Untils.untils import domain_loss_from_batch\n",
    "\n",
    "# ========================\n",
    "# CONFIG (tune these)\n",
    "# ========================\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "FOURIER = \"STFT\"             # \"FFT\" or \"STFT\"\n",
    "\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "LAMBDA_DOMAIN = 0.1          # weight for domain loss\n",
    "BATCH_CLIP_NORM = 5.0\n",
    "SAVE_PATH = \"best_model.pth\"\n",
    "\n",
    "NUM_CLASSES = len(LABEL_TO_IDX)\n",
    "# ========================\n",
    "# Model / Optim / Loss\n",
    "# ========================\n",
    "model = (CNN2D(NUM_CLASSES) if FOURIER == \"STFT\" else CNN1D(NUM_CLASSES)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# ========================\n",
    "# Evaluation utility\n",
    "# ========================\n",
    "def evaluate(loader) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    loss_sum = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, d in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            logits, _ = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return (loss_sum / total) if total > 0 else 0.0, (correct / total) if total > 0 else 0.0\n",
    "\n",
    "# ========================\n",
    "# Training loop\n",
    "# ========================\n",
    "best_score = -1.0  # dùng điểm tổng hợp 50/50\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    src_correct = src_total = 0\n",
    "    tgt_correct = tgt_total = 0\n",
    "\n",
    "    src_iter = iter(source_train_loader)\n",
    "    tgt_cycle = cycle(target_train_loader)\n",
    "\n",
    "    for xs, ys, ds in src_iter:\n",
    "        xt, yt, dt = next(tgt_cycle)\n",
    "\n",
    "        xs, ys = xs.to(DEVICE), ys.to(DEVICE)\n",
    "        xt, yt = xt.to(DEVICE), yt.to(DEVICE)\n",
    "        ds, dt = ds.to(DEVICE), dt.to(DEVICE)\n",
    "\n",
    "        # combine batches\n",
    "        x = torch.cat([xs, xt], dim=0)\n",
    "        domain_ids = torch.cat([ds, dt], dim=0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, feats = model(x)\n",
    "        bs = xs.size(0)\n",
    "\n",
    "        # classification on source\n",
    "        loss_cls = criterion(logits[:bs], ys)\n",
    "\n",
    "        # domain loss on whole batch\n",
    "        loss_domain = domain_loss_from_batch(feats, domain_ids)\n",
    "\n",
    "        loss = loss_cls + LAMBDA_DOMAIN * loss_domain\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), BATCH_CLIP_NORM)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * (xs.size(0) + xt.size(0))/ (len(source_train_loader) * source_train_loader.batch_size)\n",
    "\n",
    "\n",
    "        # metrics\n",
    "        src_correct += (logits[:bs].argmax(1) == ys).sum().item()\n",
    "        src_total   += ys.size(0)\n",
    "        tgt_correct += (logits[bs:].argmax(1) == yt).sum().item()\n",
    "        tgt_total   += yt.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    src_train_acc = src_correct / src_total\n",
    "    tgt_train_acc = tgt_correct / tgt_total\n",
    "\n",
    "    # validation\n",
    "    _, src_val_acc = evaluate(source_val_loader)\n",
    "    _, tgt_val_acc = evaluate(target_val_loader)\n",
    "\n",
    "    # ===============================\n",
    "    #  SAVE BEST MODEL (50% SRC + 50% TGT)\n",
    "    # ===============================\n",
    "    score = 0.5 * src_val_acc + 0.5 * tgt_val_acc\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"S_train: {src_train_acc:.4f} T_train: {tgt_train_acc:.4f} | \"\n",
    "        f\"S_val: {src_val_acc:.4f} T_val: {tgt_val_acc:.4f} | \"\n",
    "        f\"avg_loss: {running_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"Saved best model (epoch {epoch}) | combined = {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
